{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zhconv\n",
    "\n",
    "data = pd.read_csv(\"movies.csv\")\n",
    "data.dropna(subset=['GENRES', 'STORYLINE'], how='any', inplace=True)\n",
    "\n",
    "# 中文繁体与简体的转化\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: zhconv.convert(x, 'zh-cn'))\n",
    "data['STORYLINE'] = data['STORYLINE'].apply(lambda x: zhconv.convert(x, 'zh-cn'))\n",
    "\n",
    "# 对分类重复的样本做一个并集处理\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('动画 Animation', '动画') if \"动画 Animation\" in x.split(\"/\") else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('剧情 Drama', '剧情') if \"剧情 Drama\" in x.split(\"/\") else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('儿童 Kids', '儿童') if \"儿童 Kids\" in x.split(\"/\") else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('纪录片 Documentary', '纪录片') if \"纪录片 Documentary\" in x.split(\"/\") else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('音乐 Music', '音乐') if \"音乐 Music\" in x.split(\"/\") else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('惊悚 Thriller', '惊悚') if \"惊悚 Thriller\" in x.split(\"/\") else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('Reality-TV', '真人秀') if \"Reality-TV\" in x.split(\"/\") else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('爱情 Romance', '爱情') if \"爱情 Romance\" in x.split(\"/\") else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('Adult', '成人') if \"Adult\" in x.split(\"/\") else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('喜剧 Comedy', '喜剧') if \"喜剧 Comedy\" in x.split(\"/\") else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('传记 Biography', '传记') if \"传记 Biography\" in x.split(\"/\") else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('悬疑 Mystery', '悬疑') if \"悬疑 Mystery\" in x.split(\"/\") else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('Comedy', '喜剧') if \"Comedy\" in x.split(\"/\") else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('历史 History', '历史') if \"历史 History\" in x.split(\"/\") else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('动作 Action', '动作') if \"动作 Action\" in x.split(\"/\") else x)\n",
    "\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('惊栗', '惊悚'))\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('/荒诞', '') if ((\"喜剧\" in x) and (\"/荒诞\" in x)) else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('荒诞/', '') if ((\"喜剧\" in x) and (\"荒诞/\" in x)) else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('荒诞', '喜剧') if ((\"喜剧\" not in x.split('/')) and (\"荒诞\" in x.split('/'))) else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('悬念', '悬疑'))\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('/情色', ''))\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('情色/', ''))\n",
    "data.drop(data[data['GENRES'] == '情色'].index, inplace=True)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('/成人', ''))\n",
    "data.drop(data[data['GENRES'] == '成人'].index, inplace=True)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('/鬼怪', '') if ((\"恐怖\" in x) and (\"/鬼怪\" in x)) else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('鬼怪/', '') if ((\"恐怖\" in x) and (\"鬼怪/\" in x)) else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('鬼怪', '恐怖') if ((\"恐怖\" not in x.split('/')) and (\"鬼怪\" in x.split('/'))) else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('纪录片', '纪录'))\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('/脱口秀', ''))\n",
    "data.drop(data[data['GENRES'] == '脱口秀'].index, inplace=True)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('/短片', ''))\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('短片/', ''))\n",
    "data.drop(data[data['GENRES'] == '短片'].index, inplace=True)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('/真人秀', ''))\n",
    "data.drop(data[data['GENRES'] == '真人秀'].index, inplace=True)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('/戏曲', ''))\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('/灾难', '') if ((\"战争\" in x) and (\"/灾难\" in x)) else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('灾难/', '') if ((\"战争\" in x) and (\"灾难/\" in x)) else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('灾难', '战争') if ((\"战争\" not in x.split('/')) and (\"灾难\" in x.split('/'))) else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('/黑色电影', '') if ((\"犯罪\" in x) and (\"/黑色电影\" in x)) else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('黑色电影/', '') if ((\"犯罪\" in x) and (\"黑色电影/\" in x)) else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('黑色电影', '犯罪') if ((\"犯罪\" not in x.split('/')) and (\"黑色电影\" in x.split('/'))) else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('/同性', '') if ((\"爱情\" in x) and (\"/同性\" in x)) else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('同性/', '') if ((\"爱情\" in x) and (\"同性/\" in x)) else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('同性', '爱情') if ((\"爱情\" not in x.split('/')) and (\"同性\" in x.split('/'))) else x)\n",
    "data['GENRES'] = data['GENRES'].apply(lambda x: x.replace('/舞台艺术', ''))\n",
    "data.drop(data[data['GENRES'] == '舞台艺术'].index, inplace=True)\n",
    "\n",
    "# count = 0  # 计数器，用于记录已修改的样本数量\n",
    "#\n",
    "# # 遍历数据进行标签修改\n",
    "# for i, row in data.iterrows():\n",
    "#     genres = row['GENRES']\n",
    "#     if '剧情/' in genres:\n",
    "#         modified_genres = genres.replace('剧情/', '')\n",
    "#         data.at[i, 'GENRES'] = modified_genres\n",
    "#         count += 1\n",
    "#     elif '/剧情' in genres:\n",
    "#         modified_genres = genres.replace('/剧情', '')\n",
    "#         data.at[i, 'GENRES'] = modified_genres\n",
    "#         count += 1\n",
    "#\n",
    "#     if count == 40000:\n",
    "#         break\n",
    "#\n",
    "# count = 0\n",
    "# for i, row in data.iterrows():\n",
    "#     genres = row['GENRES']\n",
    "#     if '喜剧/' in genres:\n",
    "#         modified_genres = genres.replace('喜剧/', '')\n",
    "#         data.at[i, 'GENRES'] = modified_genres\n",
    "#         count += 1\n",
    "#     elif '/喜剧' in genres:\n",
    "#         modified_genres = genres.replace('/喜剧', '')\n",
    "#         data.at[i, 'GENRES'] = modified_genres\n",
    "#         count += 1\n",
    "#\n",
    "#     if count == 18000:\n",
    "#         break\n",
    "#\n",
    "# count = 0\n",
    "# for i, row in data.iterrows():\n",
    "#     genres = row['GENRES']\n",
    "#     if '爱情/' in genres:\n",
    "#         modified_genres = genres.replace('爱情/', '')\n",
    "#         data.at[i, 'GENRES'] = modified_genres\n",
    "#         count += 1\n",
    "#     if '/爱情' in genres:\n",
    "#         modified_genres = genres.replace('/爱情', '')\n",
    "#         data.at[i, 'GENRES'] = modified_genres\n",
    "#         count += 1\n",
    "#     if count == 13000:\n",
    "#         break\n",
    "#\n",
    "# count = 0\n",
    "# for i, row in data.iterrows():\n",
    "#     genres = row['GENRES']\n",
    "#     if '恐怖/' in genres:\n",
    "#         modified_genres = genres.replace('恐怖/', '')\n",
    "#         data.at[i, 'GENRES'] = modified_genres\n",
    "#         count += 1\n",
    "#     elif '/恐怖' in genres:\n",
    "#         modified_genres = genres.replace('/恐怖', '')\n",
    "#         data.at[i, 'GENRES'] = modified_genres\n",
    "#         count += 1\n",
    "#\n",
    "#     if count == 5000:\n",
    "#         break\n",
    "#\n",
    "# count = 0\n",
    "# for i, row in data.iterrows():\n",
    "#     genres = row['GENRES']\n",
    "#     if '惊悚/' in genres:\n",
    "#         modified_genres = genres.replace('惊悚/', '')\n",
    "#         data.at[i, 'GENRES'] = modified_genres\n",
    "#         count += 1\n",
    "#     elif '/惊悚' in genres:\n",
    "#         modified_genres = genres.replace('/惊悚', '')\n",
    "#         data.at[i, 'GENRES'] = modified_genres\n",
    "#         count += 1\n",
    "#\n",
    "#     if count == 5000:\n",
    "#         break\n",
    "#\n",
    "# count = 0\n",
    "# for i, row in data.iterrows():\n",
    "#     genres = row['GENRES']\n",
    "#     if '动作/' in genres:\n",
    "#         modified_genres = genres.replace('动作/', '')\n",
    "#         data.at[i, 'GENRES'] = modified_genres\n",
    "#         count += 1\n",
    "#     elif '/动作' in genres:\n",
    "#         modified_genres = genres.replace('/动作', '')\n",
    "#         data.at[i, 'GENRES'] = modified_genres\n",
    "#         count += 1\n",
    "#\n",
    "#     if count == 8000:\n",
    "#         break\n",
    "#\n",
    "# count = 0\n",
    "# for i, row in data.iterrows():\n",
    "#     genres = row['GENRES']\n",
    "#     if '犯罪/' in genres:\n",
    "#         modified_genres = genres.replace('犯罪/', '')\n",
    "#         data.at[i, 'GENRES'] = modified_genres\n",
    "#         count += 1\n",
    "#     elif '/犯罪' in genres:\n",
    "#         modified_genres = genres.replace('/犯罪', '')\n",
    "#         data.at[i, 'GENRES'] = modified_genres\n",
    "#         count += 1\n",
    "#\n",
    "#     if count == 4000:\n",
    "#         break\n",
    "#\n",
    "# # print(data.shape)\n",
    "data = data.reset_index(drop=True)\n",
    "# # data[['NAME', 'GENRES', \"STORYLINE\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T02:57:13.267361300Z",
     "start_time": "2023-06-01T02:57:03.428927900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9719\n"
     ]
    }
   ],
   "source": [
    "count_c = 0\n",
    "for i in data['GENRES']:\n",
    "    if \"爱情\" in i and \"/爱情\" not in i and \"爱情/\" not in i:\n",
    "        count_c += 1\n",
    "print(count_c)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T02:37:34.089144700Z",
     "start_time": "2023-06-01T02:37:34.065144Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "剧情 : 45802\n",
      "爱情 : 15805\n",
      "动作 : 13482\n",
      "历史 : 1815\n",
      "悬疑 : 6981\n",
      "科幻 : 4979\n",
      "古装 : 1299\n",
      "动画 : 5733\n",
      "喜剧 : 19094\n",
      "冒险 : 4415\n",
      "儿童 : 784\n",
      "传记 : 1937\n",
      "犯罪 : 9461\n",
      "惊悚 : 11965\n",
      "奇幻 : 3840\n",
      "战争 : 2642\n",
      "家庭 : 2938\n",
      "恐怖 : 10276\n",
      "音乐 : 2241\n",
      "歌舞 : 1984\n",
      "西部 : 586\n",
      "运动 : 758\n",
      "武侠 : 759\n",
      "纪录 : 34\n",
      "剧情 爱情 动作 历史 悬疑 科幻 古装 动画 喜剧 冒险 儿童 传记 犯罪 惊悚 奇幻 战争 家庭 恐怖 音乐 歌舞 西部 运动 武侠 纪录\n"
     ]
    }
   ],
   "source": [
    "categories = {}\n",
    "datalist = data['GENRES'].dropna().tolist()\n",
    "for film in datalist:\n",
    "    keys = categories.keys()\n",
    "    for category in film.split('/'):\n",
    "        if category in keys:\n",
    "            categories[category] += 1\n",
    "        else:\n",
    "            categories[category] = 1\n",
    "\n",
    "for key in categories.keys():\n",
    "    print(key,\":\",categories[key])\n",
    "print(' '.join(categories.keys()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T02:57:18.358333300Z",
     "start_time": "2023-06-01T02:57:18.272534600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "length = data['STORYLINE'].str.len()\n",
    "\n",
    "# 绘制直方图\n",
    "plt.hist(length, bins=range(0, 1500, 1))\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# 保存图形为PNG文件\n",
    "plt.savefig('sentence_length.png')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T02:57:24.819010800Z",
     "start_time": "2023-06-01T02:57:22.448947200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def load_stopwords():\n",
    "        \"\"\"\n",
    "        :return: 加载好的停用词列表\n",
    "        \"\"\"\n",
    "        with open('CNN/hit_stopwords.txt', 'r', encoding='UTF-8') as f1:\n",
    "            lines = f1.readlines()\n",
    "            stopwords = []\n",
    "            for line in lines:\n",
    "                stopwords.append(line.replace('\\n', ''))\n",
    "        return stopwords"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T02:57:27.842699700Z",
     "start_time": "2023-06-01T02:57:27.821932200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86994,)\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import re\n",
    "\n",
    "stop_words = load_stopwords()\n",
    "data['STORYLINE'] = data['STORYLINE'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "data['STORYLINE'] = data['STORYLINE'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "# data['STORYLINE'] = data['STORYLINE'].apply(lambda x: x.replace(\" \", \"\"))\n",
    "data['STORYLINE'] = data['STORYLINE'].apply(lambda x: ' '.join(word for word in jieba.cut(x) if word not in stop_words))\n",
    "print(data['STORYLINE'].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T02:59:35.108138600Z",
     "start_time": "2023-06-01T02:57:29.263280900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "            GENRES                                          STORYLINE\n0            剧情/爱情  电影 情定 夏天 使然 讲述 临夏 新一代 青年人 发奋图强 借助 国家 一带 一路 战略 ...\n1            动作/爱情  桀骜不驯 如龙 武功 高强 一场 比赛 中 打成 重伤 被诊 今生 不能 再用 功夫 女友 ...\n2               剧情  平民 女孩 李莉 只身 初入 曼哈顿 求学 历经 迷失 困惑 之后 努力 善良 收获 事业 ...\n3               爱情  王小波 经典 中篇小说 绿毛 水怪 改编 电影 绿毛 水怪 王小波 早期 手稿 作品 天马行...\n4            剧情/历史  年 上海 虹口 爆炸案 后 韩国 国父 金九在 褚辅成 朱爱宝 普通群众 帮助 下 逃到 嘉...\n...            ...                                                ...\n86989        剧情/历史                    六集 历史剧 讲述 拿破仑 远征 埃及 战败 流亡 历史 故事\n86990        剧情/战争  Two   young   Danes   have   joined   Free   C...\n86991           剧情  Far   out   in   the   countryside   lives   y...\n86992           剧情  Mick   is   just     years   old   but   he   ...\n86993  剧情/家庭/奇幻/冒险  爱德华 伊万 麦克 格雷格   Ewan   McGregor   饰 生性 热爱 自由 成...\n\n[86994 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GENRES</th>\n      <th>STORYLINE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>剧情/爱情</td>\n      <td>电影 情定 夏天 使然 讲述 临夏 新一代 青年人 发奋图强 借助 国家 一带 一路 战略 ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>动作/爱情</td>\n      <td>桀骜不驯 如龙 武功 高强 一场 比赛 中 打成 重伤 被诊 今生 不能 再用 功夫 女友 ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>剧情</td>\n      <td>平民 女孩 李莉 只身 初入 曼哈顿 求学 历经 迷失 困惑 之后 努力 善良 收获 事业 ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>爱情</td>\n      <td>王小波 经典 中篇小说 绿毛 水怪 改编 电影 绿毛 水怪 王小波 早期 手稿 作品 天马行...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>剧情/历史</td>\n      <td>年 上海 虹口 爆炸案 后 韩国 国父 金九在 褚辅成 朱爱宝 普通群众 帮助 下 逃到 嘉...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>86989</th>\n      <td>剧情/历史</td>\n      <td>六集 历史剧 讲述 拿破仑 远征 埃及 战败 流亡 历史 故事</td>\n    </tr>\n    <tr>\n      <th>86990</th>\n      <td>剧情/战争</td>\n      <td>Two   young   Danes   have   joined   Free   C...</td>\n    </tr>\n    <tr>\n      <th>86991</th>\n      <td>剧情</td>\n      <td>Far   out   in   the   countryside   lives   y...</td>\n    </tr>\n    <tr>\n      <th>86992</th>\n      <td>剧情</td>\n      <td>Mick   is   just     years   old   but   he   ...</td>\n    </tr>\n    <tr>\n      <th>86993</th>\n      <td>剧情/家庭/奇幻/冒险</td>\n      <td>爱德华 伊万 麦克 格雷格   Ewan   McGregor   饰 生性 热爱 自由 成...</td>\n    </tr>\n  </tbody>\n</table>\n<p>86994 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['GENRES', \"STORYLINE\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T03:04:36.339077900Z",
     "start_time": "2023-06-01T03:04:36.269783400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "612/612 [==============================] - 42s 59ms/step - loss: 0.8337 - accuracy: 0.2799 - val_loss: 0.8508 - val_accuracy: 2.2983e-04 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1576 - accuracy: 0.4279 - val_loss: 0.1533 - val_accuracy: 0.4293 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1495 - accuracy: 0.4310 - val_loss: 0.1555 - val_accuracy: 0.4293 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1428 - accuracy: 0.4460 - val_loss: 0.1402 - val_accuracy: 0.4597 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1385 - accuracy: 0.4637 - val_loss: 0.1402 - val_accuracy: 0.4851 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1350 - accuracy: 0.4816 - val_loss: 0.1367 - val_accuracy: 0.4793 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1324 - accuracy: 0.4953 - val_loss: 0.1591 - val_accuracy: 0.4795 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1297 - accuracy: 0.5048 - val_loss: 0.1377 - val_accuracy: 0.4833 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1228 - accuracy: 0.5288 - val_loss: 0.1355 - val_accuracy: 0.4983 - lr: 2.0000e-04\n",
      "Epoch 10/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1206 - accuracy: 0.5355 - val_loss: 0.1362 - val_accuracy: 0.4984 - lr: 2.0000e-04\n",
      "272/272 [==============================] - 2s 6ms/step - loss: 0.1362 - accuracy: 0.4984\n",
      "Epoch 1/10\n",
      "612/612 [==============================] - 36s 58ms/step - loss: 0.7782 - accuracy: 0.2732 - val_loss: 0.4455 - val_accuracy: 0.0274 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1607 - accuracy: 0.4244 - val_loss: 0.1733 - val_accuracy: 0.4375 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1465 - accuracy: 0.4486 - val_loss: 0.1456 - val_accuracy: 0.4432 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1391 - accuracy: 0.4730 - val_loss: 0.1383 - val_accuracy: 0.4691 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1345 - accuracy: 0.4897 - val_loss: 0.1398 - val_accuracy: 0.4607 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1304 - accuracy: 0.4986 - val_loss: 0.1351 - val_accuracy: 0.4894 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1265 - accuracy: 0.5151 - val_loss: 0.1344 - val_accuracy: 0.4979 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1234 - accuracy: 0.5262 - val_loss: 0.1339 - val_accuracy: 0.4943 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1206 - accuracy: 0.5346 - val_loss: 0.1357 - val_accuracy: 0.5015 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1184 - accuracy: 0.5417 - val_loss: 0.1365 - val_accuracy: 0.4975 - lr: 0.0010\n",
      "272/272 [==============================] - 1s 5ms/step - loss: 0.1365 - accuracy: 0.4975\n",
      "Epoch 1/10\n",
      "612/612 [==============================] - 37s 59ms/step - loss: 0.7359 - accuracy: 0.2769 - val_loss: 0.9034 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "612/612 [==============================] - 35s 56ms/step - loss: 0.1595 - accuracy: 0.4232 - val_loss: 0.1740 - val_accuracy: 0.4296 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1454 - accuracy: 0.4527 - val_loss: 0.1436 - val_accuracy: 0.4529 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1382 - accuracy: 0.4813 - val_loss: 0.1364 - val_accuracy: 0.4797 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1338 - accuracy: 0.4903 - val_loss: 0.1420 - val_accuracy: 0.4917 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1297 - accuracy: 0.5043 - val_loss: 0.1338 - val_accuracy: 0.4993 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1258 - accuracy: 0.5188 - val_loss: 0.1362 - val_accuracy: 0.4995 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1227 - accuracy: 0.5263 - val_loss: 0.1300 - val_accuracy: 0.5099 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1200 - accuracy: 0.5320 - val_loss: 0.1306 - val_accuracy: 0.5011 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1176 - accuracy: 0.5369 - val_loss: 0.1301 - val_accuracy: 0.5136 - lr: 0.0010\n",
      "272/272 [==============================] - 1s 5ms/step - loss: 0.1301 - accuracy: 0.5136\n",
      "Epoch 1/10\n",
      "612/612 [==============================] - 36s 58ms/step - loss: 0.7757 - accuracy: 0.2777 - val_loss: 0.6604 - val_accuracy: 1.1492e-04 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "612/612 [==============================] - 35s 58ms/step - loss: 0.1600 - accuracy: 0.4233 - val_loss: 0.1507 - val_accuracy: 0.4294 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1494 - accuracy: 0.4308 - val_loss: 0.1486 - val_accuracy: 0.4298 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1429 - accuracy: 0.4449 - val_loss: 0.1460 - val_accuracy: 0.4312 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "612/612 [==============================] - 35s 58ms/step - loss: 0.1382 - accuracy: 0.4639 - val_loss: 0.1386 - val_accuracy: 0.4578 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "612/612 [==============================] - 35s 58ms/step - loss: 0.1338 - accuracy: 0.4792 - val_loss: 0.1368 - val_accuracy: 0.4685 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "612/612 [==============================] - 35s 58ms/step - loss: 0.1303 - accuracy: 0.4889 - val_loss: 0.1396 - val_accuracy: 0.4629 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "612/612 [==============================] - 35s 58ms/step - loss: 0.1272 - accuracy: 0.4998 - val_loss: 0.1339 - val_accuracy: 0.4956 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "612/612 [==============================] - 35s 58ms/step - loss: 0.1242 - accuracy: 0.5113 - val_loss: 0.1334 - val_accuracy: 0.5006 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "612/612 [==============================] - 35s 58ms/step - loss: 0.1219 - accuracy: 0.5224 - val_loss: 0.1336 - val_accuracy: 0.4943 - lr: 0.0010\n",
      "272/272 [==============================] - 1s 5ms/step - loss: 0.1336 - accuracy: 0.4943\n",
      "Epoch 1/10\n",
      "612/612 [==============================] - 36s 58ms/step - loss: 0.7445 - accuracy: 0.2695 - val_loss: 0.2862 - val_accuracy: 0.4152 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "612/612 [==============================] - 35s 58ms/step - loss: 0.1634 - accuracy: 0.4171 - val_loss: 0.1918 - val_accuracy: 0.4293 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1483 - accuracy: 0.4341 - val_loss: 0.1456 - val_accuracy: 0.4348 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1400 - accuracy: 0.4661 - val_loss: 0.1395 - val_accuracy: 0.4582 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1349 - accuracy: 0.4857 - val_loss: 0.1382 - val_accuracy: 0.4825 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1321 - accuracy: 0.4938 - val_loss: 0.1382 - val_accuracy: 0.4744 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1295 - accuracy: 0.5019 - val_loss: 0.1387 - val_accuracy: 0.4776 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1236 - accuracy: 0.5183 - val_loss: 0.1359 - val_accuracy: 0.4855 - lr: 2.0000e-04\n",
      "Epoch 9/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1217 - accuracy: 0.5268 - val_loss: 0.1368 - val_accuracy: 0.4877 - lr: 2.0000e-04\n",
      "Epoch 10/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1199 - accuracy: 0.5327 - val_loss: 0.1385 - val_accuracy: 0.4816 - lr: 2.0000e-04\n",
      "272/272 [==============================] - 1s 5ms/step - loss: 0.1385 - accuracy: 0.4816\n",
      "Epoch 1/10\n",
      "612/612 [==============================] - 37s 58ms/step - loss: 0.8117 - accuracy: 0.2735 - val_loss: 0.3782 - val_accuracy: 0.0494 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "612/612 [==============================] - 35s 58ms/step - loss: 0.1669 - accuracy: 0.4170 - val_loss: 0.2682 - val_accuracy: 0.4294 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "612/612 [==============================] - 35s 58ms/step - loss: 0.1510 - accuracy: 0.4296 - val_loss: 0.1699 - val_accuracy: 0.4294 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "612/612 [==============================] - 35s 58ms/step - loss: 0.1458 - accuracy: 0.4437 - val_loss: 0.1427 - val_accuracy: 0.4504 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "612/612 [==============================] - 35s 58ms/step - loss: 0.1417 - accuracy: 0.4564 - val_loss: 0.1420 - val_accuracy: 0.4672 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1376 - accuracy: 0.4708 - val_loss: 0.1385 - val_accuracy: 0.4706 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1325 - accuracy: 0.5022 - val_loss: 0.1419 - val_accuracy: 0.4836 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1287 - accuracy: 0.5176 - val_loss: 0.1379 - val_accuracy: 0.4725 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1253 - accuracy: 0.5268 - val_loss: 0.1335 - val_accuracy: 0.4992 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1221 - accuracy: 0.5344 - val_loss: 0.1327 - val_accuracy: 0.5048 - lr: 0.0010\n",
      "272/272 [==============================] - 2s 5ms/step - loss: 0.1327 - accuracy: 0.5048\n",
      "Epoch 1/10\n",
      "612/612 [==============================] - 36s 58ms/step - loss: 0.7639 - accuracy: 0.2950 - val_loss: 0.8358 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "612/612 [==============================] - 35s 58ms/step - loss: 0.1555 - accuracy: 0.4285 - val_loss: 0.1500 - val_accuracy: 0.4292 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "612/612 [==============================] - 35s 58ms/step - loss: 0.1491 - accuracy: 0.4297 - val_loss: 0.1465 - val_accuracy: 0.4292 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "612/612 [==============================] - 35s 58ms/step - loss: 0.1438 - accuracy: 0.4433 - val_loss: 0.1509 - val_accuracy: 0.4350 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "612/612 [==============================] - 35s 58ms/step - loss: 0.1378 - accuracy: 0.4656 - val_loss: 0.1374 - val_accuracy: 0.4678 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "612/612 [==============================] - 35s 58ms/step - loss: 0.1334 - accuracy: 0.4812 - val_loss: 0.1349 - val_accuracy: 0.4854 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "612/612 [==============================] - 35s 58ms/step - loss: 0.1302 - accuracy: 0.4982 - val_loss: 0.1399 - val_accuracy: 0.4978 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1275 - accuracy: 0.5121 - val_loss: 0.1352 - val_accuracy: 0.4926 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1212 - accuracy: 0.5329 - val_loss: 0.1344 - val_accuracy: 0.4984 - lr: 2.0000e-04\n",
      "Epoch 10/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1190 - accuracy: 0.5399 - val_loss: 0.1355 - val_accuracy: 0.4978 - lr: 2.0000e-04\n",
      "272/272 [==============================] - 2s 6ms/step - loss: 0.1355 - accuracy: 0.4978\n",
      "Epoch 1/10\n",
      "612/612 [==============================] - 36s 58ms/step - loss: 0.7463 - accuracy: 0.2907 - val_loss: 0.7210 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1570 - accuracy: 0.4273 - val_loss: 0.1488 - val_accuracy: 0.4291 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1488 - accuracy: 0.4314 - val_loss: 0.1471 - val_accuracy: 0.4293 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1422 - accuracy: 0.4577 - val_loss: 0.1399 - val_accuracy: 0.4622 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1370 - accuracy: 0.4843 - val_loss: 0.1408 - val_accuracy: 0.4627 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1333 - accuracy: 0.4960 - val_loss: 0.1387 - val_accuracy: 0.4728 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1302 - accuracy: 0.5041 - val_loss: 0.1360 - val_accuracy: 0.4820 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1274 - accuracy: 0.5114 - val_loss: 0.1346 - val_accuracy: 0.5053 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1249 - accuracy: 0.5226 - val_loss: 0.1372 - val_accuracy: 0.4820 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1224 - accuracy: 0.5295 - val_loss: 0.1362 - val_accuracy: 0.4949 - lr: 0.0010\n",
      "272/272 [==============================] - 2s 5ms/step - loss: 0.1362 - accuracy: 0.4949\n",
      "Epoch 1/10\n",
      "612/612 [==============================] - 37s 58ms/step - loss: 0.7467 - accuracy: 0.2909 - val_loss: 0.5160 - val_accuracy: 0.0059 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1573 - accuracy: 0.4271 - val_loss: 0.1520 - val_accuracy: 0.4292 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1482 - accuracy: 0.4334 - val_loss: 0.1430 - val_accuracy: 0.4382 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1412 - accuracy: 0.4534 - val_loss: 0.1374 - val_accuracy: 0.4702 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1348 - accuracy: 0.4738 - val_loss: 0.1354 - val_accuracy: 0.4785 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1307 - accuracy: 0.4873 - val_loss: 0.1333 - val_accuracy: 0.4922 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1274 - accuracy: 0.4989 - val_loss: 0.1312 - val_accuracy: 0.4917 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1248 - accuracy: 0.5059 - val_loss: 0.1314 - val_accuracy: 0.4794 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1224 - accuracy: 0.5140 - val_loss: 0.1308 - val_accuracy: 0.4916 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1205 - accuracy: 0.5189 - val_loss: 0.1327 - val_accuracy: 0.4906 - lr: 0.0010\n",
      "272/272 [==============================] - 2s 5ms/step - loss: 0.1327 - accuracy: 0.4906\n",
      "Epoch 1/10\n",
      "612/612 [==============================] - 37s 59ms/step - loss: 0.7542 - accuracy: 0.2685 - val_loss: 0.9003 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1589 - accuracy: 0.4226 - val_loss: 0.1521 - val_accuracy: 0.4293 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1467 - accuracy: 0.4432 - val_loss: 0.1439 - val_accuracy: 0.4631 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1390 - accuracy: 0.4788 - val_loss: 0.1396 - val_accuracy: 0.5065 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1344 - accuracy: 0.5024 - val_loss: 0.1361 - val_accuracy: 0.5101 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1299 - accuracy: 0.5157 - val_loss: 0.1343 - val_accuracy: 0.5082 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1260 - accuracy: 0.5260 - val_loss: 0.1331 - val_accuracy: 0.5110 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1231 - accuracy: 0.5311 - val_loss: 0.1336 - val_accuracy: 0.4968 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "612/612 [==============================] - 35s 57ms/step - loss: 0.1205 - accuracy: 0.5396 - val_loss: 0.1342 - val_accuracy: 0.5133 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "612/612 [==============================] - 35s 58ms/step - loss: 0.1123 - accuracy: 0.5582 - val_loss: 0.1329 - val_accuracy: 0.5051 - lr: 2.0000e-04\n",
      "272/272 [==============================] - 2s 6ms/step - loss: 0.1329 - accuracy: 0.5051\n",
      "平均损失： 0.1345062032341957\n",
      "平均准确率： 0.497856879234314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "ename": "PermissionDeniedError",
     "evalue": "{{function_node __wrapped__MergeV2Checkpoints_device_/job:localhost/replica:0/task:0/device:CPU:0}} Failed to create a directory: /; Permission denied [Op:MergeV2Checkpoints]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mPermissionDeniedError\u001B[0m                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 96\u001B[0m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m平均损失：\u001B[39m\u001B[38;5;124m'\u001B[39m, np\u001B[38;5;241m.\u001B[39mmean(all_loss))\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m平均准确率：\u001B[39m\u001B[38;5;124m'\u001B[39m, np\u001B[38;5;241m.\u001B[39mmean(all_accuracy))\n\u001B[1;32m---> 96\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/model_cnn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     55\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mPermissionDeniedError\u001B[0m: {{function_node __wrapped__MergeV2Checkpoints_device_/job:localhost/replica:0/task:0/device:CPU:0}} Failed to create a directory: /; Permission denied [Op:MergeV2Checkpoints]"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from keras.preprocessing.text import Tokenizer\n",
    "# from keras.utils import pad_sequences\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, BatchNormalization\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "# from keras import regularizers\n",
    "# from keras.callbacks import Progbar\n",
    "#\n",
    "# with tf.device('/gpu:0'):\n",
    "#     # 读取数据集和预处理\n",
    "#     texts = data['STORYLINE'].tolist()\n",
    "#     labels = data['GENRES'].tolist()\n",
    "#\n",
    "#     # 构建标签词汇表和独热编码\n",
    "#     all_labels = set()\n",
    "#     for label in labels:\n",
    "#         labels_list = label.split('/')\n",
    "#         all_labels.update(labels_list)\n",
    "#\n",
    "#     num_labels = len(all_labels)\n",
    "#     label2index = {label: index for index, label in enumerate(all_labels)}\n",
    "#     index2label = {index: label for index, label in enumerate(all_labels)}\n",
    "#\n",
    "#     label_sequences = [[label2index[label] for label in example.split('/')] for example in labels]\n",
    "#\n",
    "#     # 转换为多标签独热编码形式\n",
    "#     one_hot_labels = []\n",
    "#     for sequence in label_sequences:\n",
    "#         one_hot_label = np.zeros(num_labels)\n",
    "#         for index in sequence:\n",
    "#             one_hot_label[index] = 1\n",
    "#         one_hot_labels.append(one_hot_label)\n",
    "#\n",
    "#     one_hot_labels = np.array(one_hot_labels)\n",
    "#\n",
    "#     # 文本预处理和特征提取\n",
    "#     max_length = 300\n",
    "#     vocab_size = 30000\n",
    "#\n",
    "#     tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
    "#     tokenizer.fit_on_texts(texts)\n",
    "#     sequences = tokenizer.texts_to_sequences(texts)\n",
    "#     padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "#\n",
    "#     # 进行10折交叉验证\n",
    "#     kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#\n",
    "#     all_loss = []\n",
    "#     all_accuracy = []\n",
    "#\n",
    "#     for train_indices, test_indices in kfold.split(padded_sequences, np.argmax(one_hot_labels, axis=1)):\n",
    "#         train_texts = padded_sequences[train_indices]\n",
    "#         train_labels = one_hot_labels[train_indices]\n",
    "#         test_texts = padded_sequences[test_indices]\n",
    "#         test_labels = one_hot_labels[test_indices]\n",
    "#\n",
    "#         # 构建卷积神经网络模型\n",
    "#         embedding_dim = 150\n",
    "#         num_filters = 128\n",
    "#         filter_sizes = [3, 4, 5]\n",
    "#         dropout_rate = 0.5\n",
    "#\n",
    "#         model = Sequential()\n",
    "#         model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
    "#         for filter_size in filter_sizes:\n",
    "#             model.add(Conv1D(num_filters, filter_size, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "#             model.add(BatchNormalization())\n",
    "#         model.add(GlobalMaxPooling1D())\n",
    "#         model.add(Dropout(dropout_rate))\n",
    "#         model.add(Dense(num_labels, activation='sigmoid'))\n",
    "#\n",
    "#         model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#\n",
    "#         batch_size = 128\n",
    "#         epochs = 10\n",
    "#\n",
    "#         # 设置回调函数\n",
    "#         early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "#         reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001)\n",
    "#         progbar = Progbar(epochs)\n",
    "#\n",
    "#         # 训练模型\n",
    "#         model.fit(train_texts, train_labels, batch_size=batch_size, epochs=epochs, callbacks=[early_stop, reduce_lr], validation_data=(test_texts, test_labels), verbose=1)\n",
    "#\n",
    "#         # 在测试集上评估模型\n",
    "#         loss, accuracy = model.evaluate(test_texts, test_labels, verbose=1)\n",
    "#         all_loss.append(loss)\n",
    "#         all_accuracy.append(accuracy)\n",
    "#\n",
    "#     # 输出交叉验证的平均损失和准确率\n",
    "#     print('平均损失：', np.mean(all_loss))\n",
    "#     print('平均准确率：', np.mean(all_accuracy))\n",
    "#     model.save(\"model_cnn\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-30T01:46:35.012491500Z",
     "start_time": "2023-05-30T00:47:07.878576600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 418ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.02328992, 0.085204  , 0.03029785, 0.17235303, 0.06231224,\n        0.01870582, 0.03733294, 0.46675217, 0.08252984, 0.00476703,\n        0.02277743, 0.06279594, 0.00828421, 0.14195608, 0.10346419,\n        0.12417864, 0.03524984, 0.0227819 , 0.08223961, 0.2134102 ,\n        0.00468586, 0.07327101, 0.11191151, 0.283091  , 0.01242748,\n        0.06955592, 0.05822654, 0.03192092, 0.01096203, 0.04383377,\n        0.15158856, 0.00363429, 0.0145539 , 0.01082283, 0.04126389,\n        0.06491952, 0.00504789, 0.01589364]], dtype=float32)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # model.save(filepath=\"model_cnn\", overwrite=True)\n",
    "# # 假设你有一个名为\"new_texts\"的列表，包含待预测的文本数据\n",
    "# new_sequence = tokenizer.texts_to_sequences([\"中年男子孔令学（范伟 饰）是东北某市双全文武学校的语文老师，他上课认真负责，无奈所面对的是一群不知天高地厚，对祖国美好文字全无兴趣的新新人类。在一次课上，他没收了女孩刘萌（白卉子 饰）的手机，之后又阻止了追求刘萌的社会青年阿祥（支一 饰）的打架行为，由此惹来了一身麻烦。阿祥每天在孔令学下班后跟踪他，声称要“帮助辛苦的孔老师接送孩子下学”，这令一向忠厚本分的孔令学颇为恐慌。为了甩掉这个死缠烂打的小青年，他每天想尽各种办法，可是女儿的学校和家庭住址终于还是被阿祥搞清楚了。在这一过程中，孔令学的生活渐渐变成了一团乱麻……\"])\n",
    "# new_padded_sequence = pad_sequences(new_sequence, maxlen=max_length, padding='post')\n",
    "# predictions = model.predict(new_padded_sequence)\n",
    "# predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-30T02:17:55.077119200Z",
     "start_time": "2023-05-30T02:17:54.601104800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, BatchNormalization\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "class DeepLearningModel:\n",
    "    def __init__(self):\n",
    "        self.texts = None\n",
    "        self.labels = None\n",
    "        self.tokenizer = None\n",
    "        self.max_length = 300\n",
    "        self.vocab_size = 30000\n",
    "        self.num_labels = None\n",
    "        self.label2index = None\n",
    "        self.index2label = None\n",
    "        self.label_sequences = None\n",
    "        self.one_hot_labels = None\n",
    "        self.padded_sequences = None\n",
    "        self.model = None\n",
    "        self.kfold = None\n",
    "        self.all_loss = []\n",
    "        self.all_accuracy = []\n",
    "\n",
    "    def preprocess_data(self, data_me):\n",
    "        self.texts = data_me['STORYLINE'].tolist()\n",
    "        self.labels = data_me['GENRES'].tolist()\n",
    "\n",
    "        all_labels = set()\n",
    "        for label in self.labels:\n",
    "            labels_list = label.split('/')\n",
    "            all_labels.update(labels_list)\n",
    "\n",
    "        self.num_labels = len(all_labels)\n",
    "        self.label2index = {label: index for index, label in enumerate(all_labels)}\n",
    "        self.index2label = {index: label for index, label in enumerate(all_labels)}\n",
    "\n",
    "        self.label_sequences = [[self.label2index[label] for label in example.split('/')] for example in self.labels]\n",
    "\n",
    "        self.one_hot_labels = []\n",
    "        for sequence in self.label_sequences:\n",
    "            one_hot_label = np.zeros(self.num_labels)\n",
    "            for index in sequence:\n",
    "                one_hot_label[index] = 1\n",
    "            self.one_hot_labels.append(one_hot_label)\n",
    "\n",
    "        self.one_hot_labels = np.array(self.one_hot_labels)\n",
    "\n",
    "        self.tokenizer = Tokenizer(num_words=self.vocab_size, oov_token='<OOV>')\n",
    "        self.tokenizer.fit_on_texts(self.texts)\n",
    "        sequences = self.tokenizer.texts_to_sequences(self.texts)\n",
    "        self.padded_sequences = pad_sequences(sequences, maxlen=self.max_length, padding='post')\n",
    "\n",
    "    def build_model(self):\n",
    "        embedding_dim = 150\n",
    "        num_filters = 128\n",
    "        filter_sizes = [3, 4, 5]\n",
    "        dropout_rate = 0.5\n",
    "\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Embedding(self.vocab_size, embedding_dim, input_length=self.max_length))\n",
    "        for filter_size in filter_sizes:\n",
    "            self.model.add(Conv1D(num_filters, filter_size, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "            self.model.add(BatchNormalization())\n",
    "            self.model.add(Conv1D(num_filters, filter_size, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "            self.model.add(BatchNormalization())\n",
    "        self.model.add(GlobalMaxPooling1D())\n",
    "        self.model.add(Dropout(dropout_rate))\n",
    "        self.model.add(Dense(self.num_labels, activation='sigmoid'))\n",
    "\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    def train_and_evaluate(self):\n",
    "        batch_size = 128\n",
    "        epochs = 10\n",
    "\n",
    "        self.kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "        for train_indices, test_indices in self.kfold.split(self.padded_sequences, np.argmax(self.one_hot_labels, axis=1)):\n",
    "            train_texts = self.padded_sequences[train_indices]\n",
    "            train_labels = self.one_hot_labels[train_indices]\n",
    "            test_texts = self.padded_sequences[test_indices]\n",
    "            test_labels = self.one_hot_labels[test_indices]\n",
    "\n",
    "            early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "            reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001)\n",
    "\n",
    "            self.model.fit(train_texts, train_labels, batch_size=batch_size, epochs=epochs,\n",
    "                           callbacks=[early_stop, reduce_lr], validation_data=(test_texts, test_labels), verbose=1)\n",
    "\n",
    "            loss, accuracy = self.model.evaluate(test_texts, test_labels, verbose=1)\n",
    "            self.all_loss.append(loss)\n",
    "            self.all_accuracy.append(accuracy)\n",
    "\n",
    "    def print_results(self):\n",
    "        print('平均损失：', np.mean(self.all_loss))\n",
    "        print('平均准确率：', np.mean(self.all_accuracy))\n",
    "\n",
    "    def save_tokenizer(self, file_path):\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(self.tokenizer, f)\n",
    "\n",
    "    def save_index2label(self, file_path):\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(self.index2label, f)\n",
    "\n",
    "    def load_index2label(self, file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            self.index2label = pickle.load(f)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_tokenizer(file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            tokenizer = pickle.load(f)\n",
    "        return tokenizer\n",
    "\n",
    "    def save_model(self, file_path):\n",
    "        self.model.save(file_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T03:04:42.178310400Z",
     "start_time": "2023-06-01T03:04:42.153406200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 63s 99ms/step - loss: 1.6652 - accuracy: 0.1918 - val_loss: 1.2504 - val_accuracy: 3.4483e-04 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "612/612 [==============================] - 62s 101ms/step - loss: 0.3247 - accuracy: 0.2598 - val_loss: 0.5337 - val_accuracy: 0.0176 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "612/612 [==============================] - 62s 101ms/step - loss: 0.2705 - accuracy: 0.2678 - val_loss: 0.6222 - val_accuracy: 0.0039 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "612/612 [==============================] - 62s 101ms/step - loss: 0.2546 - accuracy: 0.2698 - val_loss: 0.5019 - val_accuracy: 0.0223 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "612/612 [==============================] - 62s 101ms/step - loss: 0.2387 - accuracy: 0.2709 - val_loss: 0.4696 - val_accuracy: 0.0086 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "612/612 [==============================] - 62s 101ms/step - loss: 0.2452 - accuracy: 0.2732 - val_loss: 0.3566 - val_accuracy: 0.0952 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "612/612 [==============================] - 62s 101ms/step - loss: 0.2219 - accuracy: 0.2869 - val_loss: 0.2276 - val_accuracy: 0.3259 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "612/612 [==============================] - 61s 100ms/step - loss: 0.2134 - accuracy: 0.3258 - val_loss: 0.2216 - val_accuracy: 0.2953 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "612/612 [==============================] - 61s 99ms/step - loss: 0.2070 - accuracy: 0.3404 - val_loss: 0.2226 - val_accuracy: 0.2772 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "612/612 [==============================] - 61s 99ms/step - loss: 0.2029 - accuracy: 0.3481 - val_loss: 0.2184 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "272/272 [==============================] - 3s 9ms/step - loss: 0.2184 - accuracy: 0.3108\n",
      "Epoch 1/10\n",
      "612/612 [==============================] - 62s 101ms/step - loss: 0.2008 - accuracy: 0.3530 - val_loss: 0.2077 - val_accuracy: 0.3109 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "612/612 [==============================] - 62s 101ms/step - loss: 0.1958 - accuracy: 0.3626 - val_loss: 0.2211 - val_accuracy: 0.3160 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "612/612 [==============================] - 63s 103ms/step - loss: 0.1907 - accuracy: 0.3817 - val_loss: 0.1945 - val_accuracy: 0.3609 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "612/612 [==============================] - 61s 100ms/step - loss: 0.1858 - accuracy: 0.3956 - val_loss: 0.2053 - val_accuracy: 0.3495 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "612/612 [==============================] - 61s 100ms/step - loss: 0.1822 - accuracy: 0.4036 - val_loss: 0.1958 - val_accuracy: 0.3882 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "612/612 [==============================] - 62s 101ms/step - loss: 0.1692 - accuracy: 0.4282 - val_loss: 0.1955 - val_accuracy: 0.3877 - lr: 2.0000e-04\n",
      "272/272 [==============================] - 3s 9ms/step - loss: 0.1945 - accuracy: 0.3609\n",
      "Epoch 1/10\n",
      "612/612 [==============================] - 62s 101ms/step - loss: 0.1783 - accuracy: 0.4052 - val_loss: 0.1700 - val_accuracy: 0.4195 - lr: 2.0000e-04\n",
      "Epoch 2/10\n",
      "612/612 [==============================] - 62s 101ms/step - loss: 0.1739 - accuracy: 0.4131 - val_loss: 0.1690 - val_accuracy: 0.4244 - lr: 2.0000e-04\n",
      "Epoch 3/10\n",
      "612/612 [==============================] - 62s 101ms/step - loss: 0.1709 - accuracy: 0.4217 - val_loss: 0.1695 - val_accuracy: 0.4182 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "612/612 [==============================] - 61s 100ms/step - loss: 0.1681 - accuracy: 0.4290 - val_loss: 0.1722 - val_accuracy: 0.4034 - lr: 2.0000e-04\n",
      "Epoch 5/10\n",
      "612/612 [==============================] - 62s 101ms/step - loss: 0.1628 - accuracy: 0.4395 - val_loss: 0.1708 - val_accuracy: 0.4203 - lr: 1.0000e-04\n",
      "272/272 [==============================] - 2s 9ms/step - loss: 0.1690 - accuracy: 0.4244\n",
      "Epoch 1/10\n",
      "612/612 [==============================] - 62s 101ms/step - loss: 0.1697 - accuracy: 0.4245 - val_loss: 0.1618 - val_accuracy: 0.4466 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "612/612 [==============================] - 62s 101ms/step - loss: 0.1676 - accuracy: 0.4278 - val_loss: 0.1619 - val_accuracy: 0.4455 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "612/612 [==============================] - 61s 100ms/step - loss: 0.1658 - accuracy: 0.4320 - val_loss: 0.1639 - val_accuracy: 0.4391 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "612/612 [==============================] - 62s 101ms/step - loss: 0.1637 - accuracy: 0.4372 - val_loss: 0.1648 - val_accuracy: 0.4464 - lr: 1.0000e-04\n",
      "272/272 [==============================] - 2s 9ms/step - loss: 0.1618 - accuracy: 0.4466\n",
      "Epoch 1/10\n",
      "612/612 [==============================] - 63s 103ms/step - loss: 0.1678 - accuracy: 0.4287 - val_loss: 0.1601 - val_accuracy: 0.4497 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "612/612 [==============================] - 61s 100ms/step - loss: 0.1660 - accuracy: 0.4315 - val_loss: 0.1605 - val_accuracy: 0.4528 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "612/612 [==============================] - 61s 100ms/step - loss: 0.1640 - accuracy: 0.4356 - val_loss: 0.1610 - val_accuracy: 0.4333 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "612/612 [==============================] - 61s 100ms/step - loss: 0.1620 - accuracy: 0.4398 - val_loss: 0.1623 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
      "272/272 [==============================] - 2s 9ms/step - loss: 0.1601 - accuracy: 0.4497\n",
      "Epoch 1/10\n",
      "612/612 [==============================] - 62s 101ms/step - loss: 0.1662 - accuracy: 0.4314 - val_loss: 0.1599 - val_accuracy: 0.4548 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "612/612 [==============================] - 61s 99ms/step - loss: 0.1644 - accuracy: 0.4365 - val_loss: 0.1613 - val_accuracy: 0.4553 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "612/612 [==============================] - 61s 100ms/step - loss: 0.1623 - accuracy: 0.4415 - val_loss: 0.1600 - val_accuracy: 0.4486 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "612/612 [==============================] - 61s 100ms/step - loss: 0.1602 - accuracy: 0.4466 - val_loss: 0.1624 - val_accuracy: 0.4406 - lr: 1.0000e-04\n",
      "272/272 [==============================] - 2s 9ms/step - loss: 0.1599 - accuracy: 0.4548\n",
      "Epoch 1/10\n",
      "612/612 [==============================] - 61s 100ms/step - loss: 0.1645 - accuracy: 0.4354 - val_loss: 0.1581 - val_accuracy: 0.4563 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "612/612 [==============================] - 62s 101ms/step - loss: 0.1625 - accuracy: 0.4407 - val_loss: 0.1599 - val_accuracy: 0.4553 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "612/612 [==============================] - 61s 100ms/step - loss: 0.1606 - accuracy: 0.4433 - val_loss: 0.1594 - val_accuracy: 0.4405 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "612/612 [==============================] - 61s 100ms/step - loss: 0.1586 - accuracy: 0.4512 - val_loss: 0.1615 - val_accuracy: 0.4395 - lr: 1.0000e-04\n",
      "272/272 [==============================] - 2s 9ms/step - loss: 0.1581 - accuracy: 0.4563\n",
      "Epoch 1/10\n",
      "612/612 [==============================] - 62s 101ms/step - loss: 0.1627 - accuracy: 0.4391 - val_loss: 0.1562 - val_accuracy: 0.4509 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "612/612 [==============================] - 62s 101ms/step - loss: 0.1608 - accuracy: 0.4437 - val_loss: 0.1573 - val_accuracy: 0.4552 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "612/612 [==============================] - 61s 100ms/step - loss: 0.1587 - accuracy: 0.4500 - val_loss: 0.1587 - val_accuracy: 0.4395 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "612/612 [==============================] - 62s 102ms/step - loss: 0.1566 - accuracy: 0.4555 - val_loss: 0.1619 - val_accuracy: 0.4565 - lr: 1.0000e-04\n",
      "272/272 [==============================] - 2s 9ms/step - loss: 0.1562 - accuracy: 0.4509\n",
      "Epoch 1/10\n",
      "612/612 [==============================] - 62s 101ms/step - loss: 0.1610 - accuracy: 0.4436 - val_loss: 0.1550 - val_accuracy: 0.4553 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "612/612 [==============================] - 61s 100ms/step - loss: 0.1590 - accuracy: 0.4475 - val_loss: 0.1556 - val_accuracy: 0.4428 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "612/612 [==============================] - 62s 101ms/step - loss: 0.1571 - accuracy: 0.4536 - val_loss: 0.1572 - val_accuracy: 0.4545 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "612/612 [==============================] - 61s 100ms/step - loss: 0.1547 - accuracy: 0.4616 - val_loss: 0.1594 - val_accuracy: 0.4482 - lr: 1.0000e-04\n",
      "272/272 [==============================] - 2s 9ms/step - loss: 0.1550 - accuracy: 0.4553\n",
      "Epoch 1/10\n",
      "612/612 [==============================] - 61s 100ms/step - loss: 0.1593 - accuracy: 0.4482 - val_loss: 0.1516 - val_accuracy: 0.4601 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "612/612 [==============================] - 62s 101ms/step - loss: 0.1573 - accuracy: 0.4527 - val_loss: 0.1543 - val_accuracy: 0.4580 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "612/612 [==============================] - 62s 101ms/step - loss: 0.1551 - accuracy: 0.4582 - val_loss: 0.1593 - val_accuracy: 0.4520 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "612/612 [==============================] - 61s 99ms/step - loss: 0.1530 - accuracy: 0.4677 - val_loss: 0.1592 - val_accuracy: 0.4413 - lr: 1.0000e-04\n",
      "272/272 [==============================] - 2s 9ms/step - loss: 0.1516 - accuracy: 0.4601\n",
      "平均损失： 0.16847168952226638\n",
      "平均准确率： 0.42696237564086914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_cnn\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_cnn\\assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    # 创建 DeepLearningModel 实例\n",
    "    model = DeepLearningModel()\n",
    "\n",
    "    # 预处理数据\n",
    "    model.preprocess_data(data)\n",
    "\n",
    "    # 构建模型\n",
    "    model.build_model()\n",
    "\n",
    "    # 训练和评估模型\n",
    "    model.train_and_evaluate()\n",
    "\n",
    "    # 打印结果\n",
    "    model.print_results()\n",
    "\n",
    "    # 保存 tokenizer\n",
    "    model.save_tokenizer('tokenizer.pkl')\n",
    "\n",
    "    # 保存 index2label 映射\n",
    "    model.save_index2label('index2label.pkl')\n",
    "\n",
    "    # 保存模型\n",
    "    model.save_model(\"model_cnn\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T03:57:51.407673500Z",
     "start_time": "2023-06-01T03:06:56.210977300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 513ms/step\n",
      "[[0.05299962 0.01265376 0.03988634 0.09492984 0.02446835 0.24174863\n",
      "  0.04624625 0.1345361  0.01506555 0.00340834 0.0396083  0.11182404\n",
      "  0.05136602 0.01281633 0.06634751 0.37514833 0.18375367 0.03419875\n",
      "  0.00994127 0.01434876 0.00711567 0.05140505 0.01872394 0.00706302]]\n",
      "文本: 年轻的马里恩·克兰（珍妮特·利 饰）在Phoenix工作，深受老板洛厄里（沃恩·泰勒 饰）信任。男友萨姆·卢米斯（约翰·加文 饰）在Fairvale经营一家五金店，因要替亡父还债又要支付前妻赡养费而无力再婚，只能借出差的机会偶尔来与马里恩幽会。马里恩对此感到不满，于是在周五下午趁机携四万美元公款驾车潜逃。可是马里恩的潜逃之路并不顺利：先是在出城的时候被洛厄里目击，周六一大早又被警察怀疑。花了七百美元以旧车换新车之后，马里恩继续忐忑地行驶。入夜后，天降大雨，视线模糊，无法行驶，马里恩只得将车泊入路边的贝茨汽车旅馆投宿。老板诺尔曼（安东尼·珀金斯 饰）十分友善，试图邀请马里恩到家里共进晚餐，可惜被凶恶的母亲粗暴阻止，只得将晚餐端至旅馆客厅。马里恩在客厅一边进餐一边与诺尔曼交谈，终于决定周日返回Phoenix。用餐完毕，马里恩回房沐浴。这时，一个老妇的身影突然出现在卫生间……\n",
      "预测标签: ['喜剧', '动画', '动作', '剧情', '爱情']\n",
      "1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "def main():\n",
    "    # 加载 tokenizer 和 index2label 映射\n",
    "    tokenizer = DeepLearningModel.load_tokenizer('tokenizer.pkl')\n",
    "\n",
    "    # 加载 index2label 映射\n",
    "    model_me = DeepLearningModel()\n",
    "    model_me.load_index2label('index2label.pkl')\n",
    "\n",
    "    # 加载模型\n",
    "    model_me.model = load_model(\"model_cnn\")\n",
    "\n",
    "    # 准备要预测的文本数据\n",
    "    texts = [\"年轻的马里恩·克兰（珍妮特·利 饰）在Phoenix工作，深受老板洛厄里（沃恩·泰勒 饰）信任。男友萨姆·卢米斯（约翰·加文 饰）在Fairvale经营一家五金店，因要替亡父还债又要支付前妻赡养费而无力再婚，只能借出差的机会偶尔来与马里恩幽会。马里恩对此感到不满，于是在周五下午趁机携四万美元公款驾车潜逃。可是马里恩的潜逃之路并不顺利：先是在出城的时候被洛厄里目击，周六一大早又被警察怀疑。花了七百美元以旧车换新车之后，马里恩继续忐忑地行驶。入夜后，天降大雨，视线模糊，无法行驶，马里恩只得将车泊入路边的贝茨汽车旅馆投宿。老板诺尔曼（安东尼·珀金斯 饰）十分友善，试图邀请马里恩到家里共进晚餐，可惜被凶恶的母亲粗暴阻止，只得将晚餐端至旅馆客厅。马里恩在客厅一边进餐一边与诺尔曼交谈，终于决定周日返回Phoenix。用餐完毕，马里恩回房沐浴。这时，一个老妇的身影突然出现在卫生间……\"]\n",
    "\n",
    "    # 使用 tokenizer 对文本进行编码\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=model_me.max_length, padding='post')\n",
    "\n",
    "    # 进行预测\n",
    "    predictions = model_me.model.predict(padded_sequences)\n",
    "    print(predictions)\n",
    "\n",
    "    # 解析预测结果\n",
    "    predicted_labels = []\n",
    "    for prediction in predictions:\n",
    "        indices = [j for j, prob in enumerate(prediction) if prob >= 0.1]  # 设置阈值为0.5\n",
    "        labels = [model_me.index2label[index] for index in indices]\n",
    "        predicted_labels.append(labels)\n",
    "\n",
    "    # 打印预测结果\n",
    "    for text, labels in zip(texts, predicted_labels):\n",
    "        print(\"文本:\", text)\n",
    "        print(\"预测标签:\", labels)\n",
    "        print(1)\n",
    "        print()\n",
    "\n",
    "main()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T05:34:07.547959Z",
     "start_time": "2023-06-01T05:34:05.305361900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
